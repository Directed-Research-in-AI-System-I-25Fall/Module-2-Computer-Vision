{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read RGBD and camera parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rgbd_and_pose(data_root):\n",
    "    poses, intrinsics, rgbs, depths = [], [], [], []\n",
    "    # ToDo: read rgbd and camera parameters\n",
    "    pass\n",
    "    return poses, intrinsics, rgbs, depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4) (4, 4) (800, 800, 3) (800, 800)\n",
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = 'YOUR PROJECT DIR'\n",
    "poses, intrinsics, rgbs, depths = read_rgbd_and_pose(ROOT_DIR)\n",
    "print(poses[0].shape, intrinsics[0].shape, rgbs[0].shape, depths[0].shape)\n",
    "print(len(poses), len(intrinsics), len(rgbs), len(depths))\n",
    "H, W = rgbs[0].shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract mesh from RGBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_mesh(mesh, cluster_to_keep=1):\n",
    "    \"\"\"\n",
    "    Post-process a mesh to filter out floaters and disconnected parts\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    # print(\"post processing the mesh to have {} clusterscluster_to_kep\".format(cluster_to_keep))\n",
    "    print(\"post processing\")\n",
    "    mesh_0 = copy.deepcopy(mesh)\n",
    "    triangle_clusters, cluster_n_triangles, cluster_area = (mesh_0.cluster_connected_triangles())\n",
    "\n",
    "    triangle_clusters = np.asarray(triangle_clusters)\n",
    "    cluster_n_triangles = np.asarray(cluster_n_triangles)\n",
    "    cluster_area = np.asarray(cluster_area)\n",
    "\n",
    "    n_cluster = np.sort(cluster_n_triangles.copy())[-cluster_to_keep]\n",
    "    n_cluster = max(n_cluster, 50) # filter meshes smaller than 50\n",
    "\n",
    "    triangles_to_remove = cluster_n_triangles[triangle_clusters] < n_cluster\n",
    "    mesh_0.remove_triangles_by_mask(triangles_to_remove)\n",
    "    mesh_0.remove_unreferenced_vertices()\n",
    "    mesh_0.remove_degenerate_triangles()\n",
    "    return mesh_0\n",
    "\n",
    "\n",
    "class MeshExtractor(object):\n",
    "    def __init__(self, poses, intrinsics, rgbs, depths, depth_trunc=3.0, sdf_trunc=0.02, voxel_size=0.004):\n",
    "        self.poses = poses\n",
    "        self.intrinsics = intrinsics\n",
    "        self.rgbs = rgbs\n",
    "        self.depths = depths\n",
    "        self.voxel_size = voxel_size\n",
    "        self.sdf_trunc = sdf_trunc\n",
    "        self.depth_trunc = depth_trunc\n",
    "        print('voxel_size: ', self.voxel_size)\n",
    "        print('sdf_trunc: ', self.sdf_trunc)\n",
    "        print('depth_trunc: ', self.depth_trunc)\n",
    "    \n",
    "    def extract_mesh(self, post_process=True):\n",
    "        mesh = self.extract_mesh_bounded(voxel_size=self.voxel_size, sdf_trunc=self.sdf_trunc, depth_trunc=self.depth_trunc)\n",
    "        if post_process:\n",
    "            mesh = post_process_mesh(mesh)\n",
    "        return mesh\n",
    "\n",
    "    def extract_mesh_bounded(self, voxel_size, sdf_trunc, depth_trunc):\n",
    "        \"\"\"\n",
    "        Perform TSDF fusion given a fixed depth range.\n",
    "        voxel_size: the voxel size of the volume\n",
    "        sdf_trunc: truncation value\n",
    "        depth_trunc: maximum depth range, should depended on the scene's scales\n",
    "        return o3d.mesh\n",
    "        \"\"\"\n",
    "        volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "            voxel_length= voxel_size,\n",
    "            sdf_trunc=sdf_trunc,\n",
    "            color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8\n",
    "        )\n",
    "\n",
    "        for i, pose in tqdm(enumerate(self.poses), desc=\"TSDF integration\"):\n",
    "            intrinsic, rgb, depth = self.intrinsics[i], self.rgbs[i], self.depths[i]\n",
    "            # make open3d rgbd\n",
    "            rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "                o3d.geometry.Image(np.asarray(rgb, order=\"C\", dtype=np.uint8)), # rgb should be in 0-255, shape [H, W, 3]\n",
    "                o3d.geometry.Image(np.asarray(depth)), # depth should be in meters, shape [H, W, 1]\n",
    "                depth_trunc = depth_trunc, convert_rgb_to_intensity=False,\n",
    "                depth_scale = 1.0\n",
    "            )\n",
    "            intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
    "                width=W,\n",
    "                height=H,\n",
    "                cx = intrinsic[0,2].item(),\n",
    "                cy = intrinsic[1,2].item(), \n",
    "                fx = intrinsic[0,0].item(), \n",
    "                fy = intrinsic[1,1].item()\n",
    "            )\n",
    "            extrinsic = np.linalg.inv(pose)\n",
    "            volume.integrate(rgbd, intrinsic=intrinsic, extrinsic=extrinsic)\n",
    "\n",
    "        mesh = volume.extract_triangle_mesh()\n",
    "        return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size:  0.004\n",
      "sdf_trunc:  0.02\n",
      "depth_trunc:  3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSDF integration: 100it [00:01, 77.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_extractor = MeshExtractor(poses, intrinsics, rgbs, depths)\n",
    "mesh = mesh_extractor.extract_mesh(post_process=False)\n",
    "recon_path = \"mesh.ply\"\n",
    "o3d.io.write_triangle_mesh(recon_path, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_cloud(data):\n",
    "    \"\"\"\n",
    "    Visualizes a point cloud using Open3D. Supports N*3 and N*6 point clouds,\n",
    "    and accepts both NumPy arrays and PyTorch tensors.\n",
    "\n",
    "    :param data: A NumPy array or PyTorch tensor of shape (N, 3) or (N, 6).\n",
    "                 For (N, 3), it represents the (x, y, z) coordinates of the points.\n",
    "                 For (N, 6), it represents the (x, y, z, r, g, b) coordinates and colors of the points.\n",
    "    \"\"\"\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.cpu().numpy()\n",
    "\n",
    "    if data.shape[1] not in [3, 6]:\n",
    "        raise ValueError(\"The input data must have shape (N, 3) or (N, 6).\")\n",
    "\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(data[:, :3])\n",
    "\n",
    "    if data.shape[1] == 6:\n",
    "        point_cloud.colors = o3d.utility.Vector3dVector(data[:, 3:])\n",
    "\n",
    "    o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the mesh as point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_tgt_path = \"recon_tgt.ply\"\n",
    "pcd = o3d.io.read_point_cloud(recon_tgt_path)\n",
    "xyz, color = np.array(pcd.points), np.array(pcd.colors)\n",
    "visualize_point_cloud(np.concatenate((xyz, color), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.io.read_point_cloud(recon_path)\n",
    "xyz, color = np.array(pcd.points), np.array(pcd.colors)\n",
    "visualize_point_cloud(np.concatenate((xyz, color), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the reconstruction error with chamfer distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.io import load_ply\n",
    "from pytorch3d.structures import Meshes\n",
    "\n",
    "def compute_chamfer(recon_pts, gt_pts):\n",
    "\twith torch.no_grad():\n",
    "\t\trecon_pts = recon_pts.cuda()\n",
    "\t\tgt_pts = gt_pts.cuda()\n",
    "\t\tdist,_ = chamfer_distance(recon_pts, gt_pts, batch_reduction=None, single_directional=False)\n",
    "\t\tdist = dist.item()\n",
    "\treturn dist\n",
    "\n",
    "\n",
    "def compute_recon_error(recon_path, gt_path, n_samples=10000):\n",
    "    verts, faces = load_ply(recon_path)\n",
    "    recon_mesh = Meshes(verts=[verts], faces=[faces])\n",
    "    verts, faces = load_ply(gt_path)\n",
    "    gt_mesh = Meshes(verts=[verts], faces=[faces])\n",
    "\n",
    "    gt_pts = sample_points_from_meshes(gt_mesh, num_samples=n_samples)\n",
    "    recon_pts = sample_points_from_meshes(recon_mesh, num_samples=n_samples)\n",
    "    return compute_chamfer(recon_pts, gt_pts) * 1000 # convert to mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # set seed\n",
    "gt_path = \"gt.ply\"\n",
    "error = compute_recon_error(recon_path, gt_path)\n",
    "print('Chamfer Distance: {:.4f} mm'.format(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ags",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
